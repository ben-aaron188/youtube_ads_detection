, wid = unid
, within_covariates = NULL
, between = .(veracity, time_instr)
, between_covariates = NULL
, observed = NULL
, diff = NULL
, reverse_diff = FALSE
, type = 3
, white.adjust = FALSE
, detailed = FALSE
, return_aov = T
)
cohensf(11.07, 1, 288)
round(tapply(data$cause, list(data$veracity), mean), 2)
round(tapply(data$cause, list(data$veracity), sd), 2)
cohensf(0.03, 1, 288)
cohensf(1.15, 1, 288)
data_past
data$time_instr
data_past = data[data$time_instr == 'past',]
data_future = data[data$time_instr == 'future',]
ezANOVA(
data = data_past
, dv = cause
, wid = unid
, within_covariates = NULL
#, between = .(veracity, time_instr)
, between = .(veracity)
, between_covariates = NULL
, observed = NULL
, diff = NULL
, reverse_diff = FALSE
, type = 3
, white.adjust = FALSE
, detailed = FALSE
, return_aov = T
)
cohensf(2.54, 1, 288)
cohensf(2.54, 1, 131)
ezANOVA(
data = data_future
, dv = cause
, wid = unid
, within_covariates = NULL
#, between = .(veracity, time_instr)
, between = .(veracity)
, between_covariates = NULL
, observed = NULL
, diff = NULL
, reverse_diff = FALSE
, type = 3
, white.adjust = FALSE
, detailed = FALSE
, return_aov = T
)
cohensf(9.98, 1, 157)
round(tapply(data$verb, list(data$veracity, data$time_instr), mean), 2)
round(tapply(data$verb, list(data$veracity, data$time_instr), sd), 2)
ezANOVA(
data = data
, dv = verb
, wid = unid
, within_covariates = NULL
, between = .(veracity, time_instr)
#, between = .(veracity)
, between_covariates = NULL
, observed = NULL
, diff = NULL
, reverse_diff = FALSE
, type = 3
, white.adjust = FALSE
, detailed = FALSE
, return_aov = T
)
cohensf(1.74, 1, 288)
cohensf(43.29, 1, 288)
cohensf(1.16, 1, 288)
ezANOVA(
data = data_past
, dv = verb
, wid = unid
, within_covariates = NULL
#, between = .(veracity, time_instr)
, between = .(veracity)
, between_covariates = NULL
, observed = NULL
, diff = NULL
, reverse_diff = FALSE
, type = 3
, white.adjust = FALSE
, detailed = FALSE
, return_aov = T
)
cohensf(3.02, 1, 131)
ezANOVA(
data = data_future
, dv = verb
, wid = unid
, within_covariates = NULL
#, between = .(veracity, time_instr)
, between = .(veracity)
, between_covariates = NULL
, observed = NULL
, diff = NULL
, reverse_diff = FALSE
, type = 3
, white.adjust = FALSE
, detailed = FALSE
, return_aov = T
)
cohensf(0.03, 1, 157)
###HUMAN CODING ANALYSIS
files = list.files()
files[24]
###HUMAN CODING ANALYSIS
files = list.files()
files
load(files[28])
data_human_coded = merge(coding, data, by='unid')
nrow(data_human_coded)
cor(data_human_coded$why, data_human_coded$cause)
cor.test(data_human_coded$how, data_human_coded$verb)
cor.test(data_human_coded$why, data_human_coded$cause)
cor.test(data_human_coded$how, data_human_coded$verb)
(data$statement1_elapsed/data$nwords)*100/1000
(data$statement1_elapsed/data$nwords)/1000
(data$statement1_elapsed/1000/data$nwords)
#RESPONSE TIME
data$statement1_elapsed_prop = (data$statement1_elapsed/1000/data$nwords)
tapply(data$statement1_elapsed_prop, list(data$veracity, data$time_instr), mean)
tapply(data$statement1_elapsed_prop, list(data$veracity, data$time_instr), sd)
aov_responsetime <- ezANOVA(
data = data
, dv = statement1_elapsed_prop
, wid = unid
, within_covariates = NULL
, between = .(veracity, time_instr)
, between_covariates = NULL
, observed = NULL
, diff = NULL
, reverse_diff = FALSE
, type = 3
, white.adjust = FALSE
, detailed = FALSE
, return_aov = T
)
aov_responsetime
data$veracity
tapply(data$statement1_deletes_prop, list(data$veracity), mean)
tapply(data$statement1_elapsed_prop, list(data$veracity), mean)
tapply(data$statement1_elapsed_prop, list(data$veracity), sd)
#####START
#MODEL STATEMENT ANALYSIS
#EXP2
#R pipeline
#clear ws
rm(list = ls())
#load deps
require(pROC)
require(stringr)
require(splitstackshape)
require(ez)
library(MASS)
source("/Users/bennettkleinberg/Documents/Research/analysis/R_script/cohensf.R")
source("/Users/bennettkleinberg/Documents/Research/analysis/R_script/cramers_phi.R")
source("/Users/bennettkleinberg/Documents/Research/analysis/R_script/ds_between_ci.R")
source("/Users/bennettkleinberg/Documents/Research/analysis/R_script/dz_within_ci.R")
##########
#import custom AUC function
source('/Users/bennettkleinberg/Documents/Research/analysis/R_script/get_fold_average_auc.R')
#########
#set wd
setwd('/Users/bennettkleinberg/Documents/Research/outputfiles/ms_past_future/exp2/full')
files = list.files()
load('modelstatement_exp2_07082017_merged.RData')
#add descr labels
data$veracity = as.factor(data$cond_ver)
levels(data$veracity) = c('truthful', 'deceptive')
data$ms = as.factor(data$ms)
#set ner variables
data$ner_unique_prop = (data$ner_unique/data$nwords)*100
data$liwc_detailedness = data$percept + data$time.y + data$space
#set to proportions
names(data)
data[,c(77:94)] = apply(data[,c(77:94)], 2, function(x){
(x/data$nwords)*100
})
#re-name variables
names(data)[23] = "manipcheck_instructed"
names(data)[24] = "manipcheck_embedded"
names(data)[25] = "manipcheck_motivated"
#conditions as running variable
data$cond_run = data$control_cond
#exclusion based on manip. check
tapply(data$manipcheck_instructed, list(data$veracity, data$ms), mean)
data$failed_manip_check = ifelse((data$veracity == 'truthful' & data$manipcheck_instructed != -1) | (data$veracity == 'deceptive' & data$manipcheck_instructed != 1), 1, 0)
table(data$failed_manip_check)
chisq.test(data$failed_manip_check, data$cond_run, correct = F)
CramersV(0.75, 320, 4)
data = data[data$failed_manip_check == 0, ]
#descriptives
table(data$veracity, data$ms)
table(data$gender, data$veracity, data$ms)
1-tapply(as.numeric(data$gender)-1, list(data$veracity, data$ms), mean)
round(tapply(data$age, list(data$veracity, data$ms), mean), 2)
round(tapply(data$age, list(data$veracity, data$ms), sd), 2)
chisq.test(data$gender, data$cond_run, correct = F)
CramersV(1.02, 385, 4)
summary(aov(data$age ~ data$cond_run))
cohensf(0.24, 1, 383)
(data$statement1_elapsed/1000/data$nwords)
#elapsed time
data$statement1_elapsed_prop = (data$statement1_elapsed/1000/data$nwords)
#no. of words
round(tapply(data$nwords, list(data$veracity, data$ms), mean), 2)
round(tapply(data$nwords, list(data$veracity, data$ms), sd), 2)
ezANOVA(
data = data
, dv = nwords
, wid = unid
, within_covariates = NULL
, between = .(veracity, ms)
#, between = .(veracity)
, between_covariates = NULL
, observed = NULL
, diff = NULL
, reverse_diff = FALSE
, type = 3
, white.adjust = FALSE
, detailed = FALSE
, return_aov = T
)
cohensf(1.19, 1, 381)
cohensf(86.16, 1, 381)
#elapsed time
data$statement1_elapsed_prop = (data$statement1_elapsed/1000/data$nwords)
tapply(data$statement1_elapsed_prop, list(data$veracity, data$time_instr), mean)
tapply(data$statement1_elapsed_prop, list(data$veracity, data$ms), mean)
tapply(data$statement1_elapsed_prop, list(data$veracity, data$ms), sd)
aov_responsetime <- ezANOVA(
data = data
, dv = statement1_elapsed_prop
, wid = unid
, within_covariates = NULL
, between = .(veracity, ms)
, between_covariates = NULL
, observed = NULL
, diff = NULL
, reverse_diff = FALSE
, type = 3
, white.adjust = FALSE
, detailed = FALSE
, return_aov = T
)
aov_responsetime
cohensf(7.77, 1, 381)
cohensf(.54, 1, 288)
tapply(data$statement1_elapsed_prop, list(data$veracity), mean)
tapply(data$statement1_elapsed_prop, list(data$veracity), sd)
(data$nwords/data$statement1_elapsed/1000)
#elapsed time
data$statement1_elapsed_prop = (data$statement1_elapsed/1000/data$nwords)
tapply(data$statement1_elapsed_prop, list(data$veracity), mean)
tapply(data$statement1_elapsed_prop, list(data$veracity), sd)
###############################################################################
##### YOUTUBE ADS DETECTION #####
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(caret)
require(e1071)
require(pROC)
require(tm)
require(ggplot2)
require(tidyr)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
source('./spacy_ner_r.R')
source('./spacy_pos_r.R')
## set dir
setwd('/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/youtube_ads/data/dataset/separated')
require(data.table)
# LOAD DATA
liwc_pos = as.data.frame(fread('liwc_pos.txt'
, header=T))
head(liwc_pos)
liwc_neg = as.data.frame(fread('liwc_neg.txt'
, header=T))
sep_pos = txt_df_from_dir(dirpath = './pos'
, include_processed = T)
dyn.load('/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
require(rJava)
library(qdap)
library(openNLP)
sep_pos = txt_df_from_dir(dirpath = './pos'
, include_processed = T)
## set dir
setwd('/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/youtube_ads/data/dataset/separated')
sep_pos = txt_df_from_dir(dirpath = './pos'
, include_processed = T)
View(head(sep_pos))
sep_neg = txt_df_from_dir(dirpath = './neg'
, include_processed = T)
# MERGE WITH LIWC DATA
names(sep_neg)
# MERGE WITH LIWC DATA
pos = merge(sep_pos, liwc_pos, by = 'Filename')
dim(pos)
neg = merge(sep_neg, liwc_neg, by = 'Filename')
dim(neg)
pos$Filename
# MERGE WITH LIWC DATA
pos = merge(sep_pos, liwc_pos, by = 'Filename')
pos$valence = 'pos'
pos$Filename_val = paste(as.character(pos$Filename), 'pos', sep = "_")
neg = merge(sep_neg, liwc_neg, by = 'Filename')
neg$valence = 'neg'
neg$Filename_val = paste(as.character(neg$Filename), 'neg', sep = "_")
neg$Filename_val
# MERGE WITH LIWC DATA
names(pos)
pos = merge(sep_pos, liwc_pos, by = 'Filename')
pos$valence = 'pos'
pos$Filename_val = paste(as.character(pos$Filename), 'pos', sep = "_")
neg = merge(sep_neg, liwc_neg, by = 'Filename')
neg$valence = 'neg'
neg$Filename_val = paste(as.character(neg$Filename), 'neg', sep = "_")
data = rbind(pos, neg)
dim(data)
require(quanteda)
require(MLmetrics)
unigrams = dfm(data$text
, ngrams = 1
, verbose = T
, remove_punct = T
, remove = stopwords("english")
, stem = F
)
bigrams = dfm(data$text
, ngrams = 2
, verbose = T
, remove_punct = T
, remove = stopwords("english")
, stem = F
)
trigrams = dfm(data$text
, ngrams = 3
, verbose = T
, remove_punct = T
, remove = stopwords("english")
, stem = F
)
bigrams_plus = dfm(data$text
, ngrams = 1:2
, verbose = T
, remove_punct = T
, remove = stopwords("english")
, stem = F
)
trigrams_plus = dfm(data$text
, ngrams = 1:3
, verbose = T
, remove_punct = T
, remove = stopwords("english")
, stem = F
)
unigrams = dfm_trim(unigrams, sparsity = param_sparsity)
# FEATURE EXTRACTION
## ngrams
### set sparsity
param_sparsity = .95
unigrams = dfm_trim(unigrams, sparsity = param_sparsity)
bigrams = dfm_trim(bigrams, sparsity = param_sparsity)
trigrams = dfm_trim(trigrams, sparsity = param_sparsity)
bigrams_plus = dfm_trim(bigrams_plus, sparsity = param_sparsity)
trigrams_plus = dfm_trim(trigrams_plus, sparsity = param_sparsity)
## merge ngrams to minimal dataframe
df_unigrams = as.data.frame(unigrams)
row.names(df_unigrams)
unigrams
# load class labels
class_labels = read.csv('../class_dict.csv')
# load class labels
class_labels = read.csv('../class_dict.csv')
names(class_labels)
# load class labels
class_labels = read.csv('../class_dict.csv', header = F)
names(class_labels)
nrow(data)
nrow(class_labels)
# LOAD CLASS LABELS
class_labels = read.csv('../class_dict.csv', header = F)
nrow(data)
class_labels
names(class_labels) = c('id', 'class')
class_labels
nrow(liwc_pos)
nrow(liwc_neg)
###############################################################################
##### YOUTUBE ADS DETECTION #####
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(caret)
require(e1071)
require(pROC)
require(tm)
require(data.table)
require(ggplot2)
require(tidyr)
require(quanteda)
require(MLmetrics)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
source('./spacy_ner_r.R')
source('./spacy_pos_r.R')
## set dir
setwd('/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/youtube_ads/data/dataset/separated')
# LOAD CLASS LABELS
class_labels = read.csv('../class_dict.csv', header = F)
names(class_labels) = c('id', 'class')
liwc_pos = as.data.frame(fread('liwc_pos.txt'
, header=T))
liwc_neg = as.data.frame(fread('liwc_neg.txt'
, header=T))
sep_pos = txt_df_from_dir(dirpath = './pos'
, include_processed = T)
sep_neg = txt_df_from_dir(dirpath = './neg'
, include_processed = T)
library(data.table)
dyn.load('/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
require(rJava)
library(qdap)
library(openNLP)
sep_pos = txt_df_from_dir(dirpath = './pos'
, include_processed = T)
## set dir
setwd('/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/youtube_ads/data/dataset/separated')
sep_pos = txt_df_from_dir(dirpath = './pos'
, include_processed = T)
###############################################################################
##### YOUTUBE ADS DETECTION #####
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(caret)
require(e1071)
require(pROC)
require(tm)
require(data.table)
require(ggplot2)
require(tidyr)
require(quanteda)
require(MLmetrics)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
source('./spacy_ner_r.R')
source('./spacy_pos_r.R')
## set dir
setwd('/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/youtube_ads/data/dataset/separated')
# LOAD CLASS LABELS
class_labels = read.csv('../class_dict.csv', header = F)
names(class_labels) = c('id', 'class')
# LOAD DATA
liwc_pos = as.data.frame(fread('liwc_pos.txt'
, header=T))
liwc_neg = as.data.frame(fread('liwc_neg.txt'
, header=T))
sep_pos = txt_df_from_dir(dirpath = './pos'
, include_processed = T)
###############################################################################
##### YOUTUBE ADS DETECTION #####
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(caret)
require(e1071)
require(pROC)
require(tm)
require(data.table)
require(ggplot2)
require(tidyr)
#require(quanteda)
#require(MLmetrics)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
source('./spacy_ner_r.R')
source('./spacy_pos_r.R')
## set dir
setwd('/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/youtube_ads/data/dataset/separated')
# LOAD CLASS LABELS
class_labels = read.csv('../class_dict.csv', header = F)
names(class_labels) = c('id', 'class')
# LOAD DATA
liwc_pos = as.data.frame(fread('liwc_pos.txt'
, header=T))
liwc_neg = as.data.frame(fread('liwc_neg.txt'
, header=T))
sep_pos = txt_df_from_dir(dirpath = './pos'
, include_processed = T)
